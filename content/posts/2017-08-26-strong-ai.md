---
title: Androids, the Mind/Body Problem, and Strong AI
date: 2017-08-26
layout: post.njk
tags: Christian, Worldviews, AI
publish: draft
excerpt: |
  Is the mind separate from the physical brain? As a Christian, I hold to the dualistic view of the mind/body problem, which argues that the mind or soul is a distinct spiritual entity separate from the physical body, leading me to conclude that true general or strong AI will never be possible.
---

_This post is adapted from an assignment I completed for the course Philosophy and Contemporary Ideas at Liberty University._

**TODO: Add introduction**

In defending Data, Picard exhibits the materialistic view of the mind/body problem when he states that "we too are machines, just machines of a different type". As Hasker (1983) points out, the materialistic position holds that "the human brain is a self-operating computer" and that the mental properties of humans are simply the result of physical processes (p. 70). A human's mind and consciousness are nothing more than properties of the physical brain, and as a result, computers, given sufficient computing power and complex enough software, could also exhibit mental properties and have consciousness. Thus it is only natural and expected that Picard, holding to naturalism, would treat Data, though just a machine, as a machine like a human machine and therefore as sentient and having rights like a human.

Maddox, on the other hand, clearly rejects that humans are machines when he differentiates Data as a machine and not a person like a human and argues that Data has no right to resign but is the property of Starfleet. In doing so, he rejects materialism, the view held by Picard. Instead, he exhibits a dualistic view of the mind/body problem when he claims that Picard is endowing Data with human attributes because it looks like a human and not a box on wheels, implying that humans have a mind or soul and are more than just machines. Because the mind is completely nonphysical in dualism, it cannot be generated through biological processes (Hasker, 1983, p. 67); thus a machine, which is not biological and merely software and computer chips, could also not generate a mind or soul.

Quite interestingly, at the end of the episode, Maddox switches from describing Data as an "it" to saying "he's remarkable."" It's not clear how much Maddox's views of Data have changed or whether he completely recognizes Data as a person, but this change in pronouns may indicate that Maddox has accepted Emergentism, the view that the mind or "soul-field" is produced by the physical body (Hasker, 1983, p. 73). If Maddox does indeed recognize Data as a person, this view could explain how an android, built by computer scientists, could become a person, have a mind, and deserve rights like a human by building software complex enough to create a "soul-field" as a result of the software and computer chips.

Data, the android presented in this Star Trek episode, is just a fictional machine that had been given human-like intelligence; strong AI, as this level of human-like artificial intelligence is known as (**TODO: Include definition and reference from https://www.ocf.berkeley.edu/~arihuang/academic/research/strongai3.html**), is not yet possible today. Recent examples of the current state of AI research include Google DeepMind's [AlphaGo beating the reigning Go champion](https://deepmind.com/research/alphago/) and [another DeepMind AI](https://deepmind.com/blog/producing-flexible-behaviours-simulated-environments/) learning basic walking skills and obstacle avoidance. Will strong AI as presented in this Star Trek episode ever be possible? It's easy to imagine code running in a super computer or a human-like robot as being self-aware and sentient, but to illustrate the implications of this possibility, consider this example: [someone recently built a 4-bit calculator](https://lapinozz.github.io/learning/2016/11/19/calculator-with-caordboard-and-marbles.html) (a very basic computer) out of nothing but cardboard, marbles, and glue. If strong AI is possible with nothing but software, and a large enough cardboard computer could be built, then cardboard and marbles, when arranged in the right configuration, could become sentient, be self-aware, think rationally, and have moral values. **TODO: Break into separate paragraph about materialism** Intuitively, this is absurd and shows the problem with materialism - how could simple physical components, such as silicon chips or cardboard and marbles, become conscious and think for itself?

**TODO: Expand this paragraph to add a better defense, and reference https://www.str.org/article/all-brain-no-mind**
As a Christian, I strongly believe that artificial intelligence as illustrated by Data will never be possible, that cardboard and marbles will never become sentient, and that strong AI will never be created. The Bible teaches that man is more than just a physical process, for "the LORD God formed man of the dust of the ground, and breathed into his nostrils the breath of life; and man became a living being." (Genesis 2:7, New King James Version) and "God created man in His own image" (Genesis 1:27, NKJV). Being made in the image of God and having a soul gives man his mental abilities and his abilities to think rationally, have moral values, and worship his Creator (see [Man: The image of God](https://answersingenesis.org/who-is-god/creator-god/man-the-image-of-god/) from Answers in Genesis). Thus the Bible quite clearly teaches some form of dualism with man having a physical body and a soul and that materialism is false. This means that no matter how complex software will become, nor how powerful computer chips will be, strong AI will never be achieved.

**TODO: Add paragraph about moral law and AIs being programmed or learning to do evil (like a parot mimics)**

**TODO: Insert conclusion**

**References**

Hasker, W. (1935). _Metaphysics: Constructing a world view_. Downers Grove, Illinois: IVP Academic
